use burn::{
    nn::{
        conv::{Conv2d, Conv2dConfig, ConvTranspose2d, ConvTranspose2dConfig},
        pool::{AdaptiveAvgPool2d, AdaptiveAvgPool2dConfig},
        BatchNorm, BatchNormConfig, LeakyRelu, LeakyReluConfig, Linear, LinearConfig, Tanh,
    },
    prelude::*,
};

#[derive(Module, Debug)]
pub struct FcBlock<B: Backend> {
    fc: Linear<B>,
    bn: BatchNorm<B, 0>,
    ac: LeakyRelu,
}
impl<B: Backend> FcBlock<B> {
    pub fn forward(&self, input: Tensor<B, 2>) -> Tensor<B, 2> {
        let output = self.fc.forward(input);
        let output = self.bn.forward(output);
        let output = self.ac.forward(output);
        output
    }
}

#[derive(Module, Debug)]
pub struct ConvBlock<B: Backend> {
    cv: Conv2d<B>,
    bn: BatchNorm<B, 2>,
    ac: LeakyRelu,
}
impl<B: Backend> ConvBlock<B> {
    pub fn forward(&self, input: Tensor<B, 4>) -> Tensor<B, 4> {
        let output = self.cv.forward(input);
        let output = self.bn.forward(output);
        let output = self.ac.forward(output);
        output
    }
}

#[derive(Module, Debug)]
pub struct DeconvBlock<B: Backend> {
    de: ConvTranspose2d<B>,
    bn: BatchNorm<B, 2>,
    ac: LeakyRelu,
}
impl<B: Backend> DeconvBlock<B> {
    pub fn forward(&self, input: Tensor<B, 4>) -> Tensor<B, 4> {
        let output = self.de.forward(input);
        let output = self.bn.forward(output);
        let output = self.ac.forward(output);
        output
    }
}

/// Generator
/// ---------
/// The generator is a deconvolutional network. It takes a 1D latent tensor,
/// which is just noise, and generates a 2D image tensor.
#[derive(Module, Debug)]
pub struct Generator<B: Backend> {
    pub fc_block1: FcBlock<B>,
    pub fc_block2: FcBlock<B>,
    pub de_block1: DeconvBlock<B>,
    pub de: ConvTranspose2d<B>,
    pub tanh: Tanh,
}
impl<B: Backend> Generator<B> {
    pub fn forward(&self, noise: Tensor<B, 2>) -> Tensor<B, 4> {
        // prepare noise for propogation through network
        let [batch_size, _] = noise.dims();
        let x = noise;

        // linear layers
        let x = self.fc_block1.forward(x);
        let x = self.fc_block2.forward(x);

        // reshape to 16x7x7 feature maps
        let x = x.reshape([batch_size, 16, 7, 7]);

        // deconvolutional layers
        let x = self.de_block1.forward(x);
        let x = self.de.forward(x);
        let x = self.tanh.forward(x);

        x
    }
}

/// Discriminator
/// -------------
/// The discriminator is a binary categorisation convolutional network, it
/// takes a 2D image tensor and predicts whether it is a real image or one
/// which has been generated by the generator network.
#[derive(Module, Debug)]
pub struct Discriminator<B: Backend> {
    cv_block1: ConvBlock<B>,
    cv_block2: ConvBlock<B>,
    pool: AdaptiveAvgPool2d,
    fc_block1: FcBlock<B>,
    fc: Linear<B>,
    tanh: Tanh,
}
impl<B: Backend> Discriminator<B> {
    /// # Shapes
    ///   - Images [batch_size, channels, height, width]
    ///   - Output [batch_size, discrimination]
    pub fn forward(&self, images: Tensor<B, 4>) -> Tensor<B, 2> {
        // prepare images for propogation through network
        let [batch_size, _, _, _] = images.dims();
        let x = images;

        // convolutional layers
        let x = self.cv_block1.forward(x); // [batch_size, 8, _, _]
        let x = self.cv_block2.forward(x); // [batch_size, 16, _, _]

        // reshape to 1D tensor
        let x = self.pool.forward(x); // [batch_size, 16, 8, 8]
        let x = x.reshape([batch_size, 16 * 8 * 8]);

        // linear layers
        let x = self.fc_block1.forward(x);
        let x = self.fc.forward(x); // [batch_size, 2]
        let x = self.tanh.forward(x);

        x
    }
}

#[derive(Module, Debug)]
pub struct Model<B: Backend> {
    pub generator: Generator<B>,
    pub discriminator: Discriminator<B>,
}

// Config for constructing and saving my Neural Network
#[derive(Config, Debug)]
pub struct ModelConfig {
    #[config(default = 10)]
    pub latent_dims: usize,
    #[config(default = 28)]
    pub image_height: usize,
    #[config(default = 28)]
    pub image_width: usize,
    #[config(default = 1)]
    pub channels: usize,
}
impl ModelConfig {
    /// Returns the initialized model.
    pub fn init<B: Backend>(&self, device: &B::Device) -> Model<B> {
        let hidden_size = 512;

        // construct the generator network
        let generator = Generator {
            fc_block1: FcBlock {
                fc: LinearConfig::new(self.latent_dims, hidden_size).init(device),
                bn: BatchNormConfig::new(hidden_size).init(device),
                ac: LeakyReluConfig::new().init(),
            },
            fc_block2: FcBlock {
                fc: LinearConfig::new(hidden_size, 16 * 7 * 7).init(device),
                bn: BatchNormConfig::new(16 * 7 * 7).init(device),
                ac: LeakyReluConfig::new().init(),
            },
            de_block1: DeconvBlock {
                de: ConvTranspose2dConfig::new([16, 8], [3, 3])
                    .with_stride([2, 2])
                    .with_padding([1, 1])
                    .with_padding_out([1, 1])
                    .init(device),
                bn: BatchNormConfig::new(8).init(device),
                ac: LeakyReluConfig::new().init(),
            },
            de: ConvTranspose2dConfig::new([8, 1], [3, 3])
                .with_stride([2, 2])
                .with_padding([1, 1])
                .with_padding_out([1, 1])
                .init(device),
            tanh: Tanh::new(),
        };

        // construct the discriminator network
        let discriminator = Discriminator {
            cv_block1: ConvBlock {
                cv: Conv2dConfig::new([self.channels, 8], [3, 3]).init(device),
                bn: BatchNormConfig::new(8).init(device),
                ac: LeakyReluConfig::new().init(),
            },
            cv_block2: ConvBlock {
                cv: Conv2dConfig::new([8, 16], [3, 3]).init(device),
                bn: BatchNormConfig::new(16).init(device),
                ac: LeakyReluConfig::new().init(),
            },
            pool: AdaptiveAvgPool2dConfig::new([8, 8]).init(),
            fc_block1: FcBlock {
                fc: LinearConfig::new(16 * 8 * 8, hidden_size).init(device),
                bn: BatchNormConfig::new(hidden_size)
                    .with_epsilon(0.8)
                    .init(device),
                ac: LeakyReluConfig::new().init(),
            },
            fc: LinearConfig::new(hidden_size, 2).init(device),
            tanh: Tanh::new(),
        };

        Model {
            generator,
            discriminator,
        }
    }
}
